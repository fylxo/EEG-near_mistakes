#!/usr/bin/env python3
"""
Parallelism Results Analysis

This script analyzes your parallelism test results and provides clear
recommendations for when to use parallel vs sequential processing.
"""

import matplotlib.pyplot as plt
import numpy as np
from dataclasses import dataclass
from typing import List, Dict


@dataclass
class BenchmarkResult:
    method: str
    time_seconds: float
    memory_mb: float
    n_jobs: int = 1
    
    @property
    def speedup(self) -> float:
        """Speedup relative to sequential baseline."""
        return getattr(self, '_baseline_time', self.time_seconds) / self.time_seconds
    
    def set_baseline(self, baseline_time: float):
        """Set baseline time for speedup calculation."""
        self._baseline_time = baseline_time


def analyze_your_results():
    """Analyze the results you provided."""
    print("ðŸ“Š ANALYSIS OF YOUR PARALLELISM RESULTS")
    print("=" * 50)
    
    # Your reported results
    results = [
        BenchmarkResult("Sequential", 5.90, 286.9, 1),
        BenchmarkResult("Multiprocessing", 7.62, 213.4, 2),
        BenchmarkResult("Threading", 2.01, 1.2, 2),
        BenchmarkResult("Multiprocessing", 4.54, 0.1, 4),
        BenchmarkResult("Threading", 2.32, -0.5, 4),  # Note: negative memory is measurement artifact
    ]
    
    # Set baseline
    baseline_time = 5.90
    for result in results:
        result.set_baseline(baseline_time)
    
    print("ðŸ“‹ YOUR RESULTS SUMMARY:")
    print("-" * 40)
    print(f"{'Method':<15} {'Jobs':<5} {'Time(s)':<8} {'Memory(MB)':<12} {'Speedup':<8} {'Status'}")
    print("-" * 60)
    
    for result in results:
        speedup = result.speedup
        if speedup > 1.5:
            status = "âœ… Good"
        elif speedup > 1.1:
            status = "âš ï¸  Marginal"
        else:
            status = "âŒ Slower"
        
        # Handle negative memory (measurement artifact)
        memory_str = f"{abs(result.memory_mb):.1f}" if result.memory_mb >= 0 else f"~{abs(result.memory_mb):.1f}"
        
        print(f"{result.method:<15} {result.n_jobs:<5} {result.time_seconds:<8.2f} "
              f"{memory_str:<12} {speedup:<8.2f} {status}")
    
    print("\nðŸ” KEY INSIGHTS FROM YOUR RESULTS:")
    print("-" * 40)
    
    print("1. ðŸ§µ THREADING OUTPERFORMED MULTIPROCESSING")
    print("   â€¢ Threading 2 jobs: 2.94x speedup (5.90s â†’ 2.01s)")
    print("   â€¢ Multiprocessing 2 jobs: 0.77x speedup (5.90s â†’ 7.62s)")
    print("   â€¢ Reason: NumPy releases GIL, threading avoids process overhead")
    
    print("\n2. ðŸ’¾ THREADING USES MUCH LESS MEMORY")
    print("   â€¢ Sequential: 286.9 MB")
    print("   â€¢ Threading: ~1.2 MB (shared memory)")
    print("   â€¢ Multiprocessing: ~213 MB (duplicated data)")
    
    print("\n3. ðŸ“ˆ DIMINISHING RETURNS WITH MORE THREADS")
    print("   â€¢ 2 threads: 2.94x speedup")
    print("   â€¢ 4 threads: 2.54x speedup")
    print("   â€¢ Reason: Limited parallelizable work in single session")
    
    print("\n4. âš–ï¸  PROCESS OVERHEAD IS SIGNIFICANT")
    print("   â€¢ Small problem size (6 channels, 1 session)")
    print("   â€¢ Process creation time competes with computation time")
    print("   â€¢ Threading has minimal overhead")
    
    return results


def predict_multisession_performance():
    """Predict performance for multi-session scenarios."""
    print("\nðŸ”® PREDICTED MULTI-SESSION PERFORMANCE")
    print("=" * 50)
    
    # Your single session results
    single_session_seq = 5.90
    single_session_threading = 2.01
    single_session_mp = 7.62
    
    # Typical rat session counts
    session_counts = [3, 6, 10, 20, 30]
    
    print("Estimated times for different session counts:")
    print(f"{'Sessions':<10} {'Sequential':<12} {'Threading':<12} {'Multiproc':<12} {'Best Method'}")
    print("-" * 60)
    
    for n_sessions in session_counts:
        seq_time = single_session_seq * n_sessions
        thread_time = single_session_threading * n_sessions
        mp_time = single_session_mp * n_sessions
        
        # For multiprocessing, assume overhead becomes less significant
        # with more sessions (amortized across larger workload)
        mp_efficiency_factor = min(1.0, 0.5 + 0.5 * (n_sessions / 10))
        mp_time_adjusted = mp_time * mp_efficiency_factor
        
        best_time = min(thread_time, mp_time_adjusted)
        best_method = "Threading" if best_time == thread_time else "Multiproc"
        
        print(f"{n_sessions:<10} {seq_time/60:<12.1f} {thread_time/60:<12.1f} "
              f"{mp_time_adjusted/60:<12.1f} {best_method}")
    
    print("\n(Times in minutes)")


def create_recommendation_framework():
    """Create clear recommendations for when to use parallelism."""
    print("\nðŸ’¡ PARALLELISM RECOMMENDATION FRAMEWORK")
    print("=" * 50)
    
    recommendations = [
        {
            'scenario': 'Single Session Analysis',
            'problem_size': 'Small (â‰¤8 channels)',
            'recommendation': 'âš ï¸  Use Sequential',
            'reason': 'Overhead > benefit'
        },
        {
            'scenario': 'Single Session Analysis', 
            'problem_size': 'Large (â‰¥16 channels)',
            'recommendation': 'âœ… Use Threading (2-4 jobs)',
            'reason': 'Good speedup, low memory'
        },
        {
            'scenario': 'Multi-Session (3-6 sessions)',
            'problem_size': 'Any ROI size',
            'recommendation': 'âœ… Use Threading (2 jobs)',
            'reason': 'Consistent speedup'
        },
        {
            'scenario': 'Multi-Session (â‰¥10 sessions)',
            'problem_size': 'Any ROI size', 
            'recommendation': 'âœ… Use Threading (4 jobs) or Multiprocessing (2 jobs)',
            'reason': 'Overhead amortized'
        },
        {
            'scenario': 'Memory-Efficient Pipeline',
            'problem_size': 'Full rat analysis',
            'recommendation': 'âœ… Use Threading (2-4 jobs)',
            'reason': 'Best balance of speed/memory'
        },
        {
            'scenario': 'Batch Processing Multiple Rats',
            'problem_size': 'Large scale',
            'recommendation': 'âœ… Use Multiprocessing (2 jobs)',
            'reason': 'True parallelism needed'
        }
    ]
    
    print(f"{'Scenario':<25} {'Problem Size':<15} {'Recommendation':<25} {'Reason'}")
    print("-" * 85)
    
    for rec in recommendations:
        print(f"{rec['scenario']:<25} {rec['problem_size']:<15} "
              f"{rec['recommendation']:<25} {rec['reason']}")


def create_usage_guide():
    """Create practical usage guide."""
    print("\nðŸ› ï¸  PRACTICAL USAGE GUIDE")
    print("=" * 50)
    
    print("ðŸ“ WHEN TO USE THREADING:")
    print("âœ… NumPy-heavy computations (spectrograms, FFTs)")
    print("âœ… Shared memory is important")
    print("âœ… Moderate parallelism (2-4 jobs)")
    print("âœ… Memory-constrained environments")
    
    print("\nðŸ“ WHEN TO USE MULTIPROCESSING:")
    print("âœ… Large-scale batch processing")
    print("âœ… CPU-bound non-NumPy operations")
    print("âœ… When you have many CPU cores available")
    print("âœ… Independent task processing")
    
    print("\nðŸ“ WHEN TO STAY SEQUENTIAL:")
    print("âš ï¸  Single session, small ROI (â‰¤8 channels)")
    print("âš ï¸  Quick prototyping/testing")
    print("âš ï¸  Memory-limited systems")
    print("âš ï¸  Debugging (easier to trace)")
    
    print("\nâš™ï¸  OPTIMAL CONFIGURATIONS:")
    print("ðŸ”§ Single session + large ROI: Threading, 2-4 jobs")
    print("ðŸ”§ Multi-session (6+ sessions): Threading, 2-4 jobs")  
    print("ðŸ”§ Memory-efficient pipeline: Threading, 2 jobs")
    print("ðŸ”§ Multiple rats: Multiprocessing, 2 jobs")
    
    print("\nðŸ“Š EXPECTED PERFORMANCE GAINS:")
    print("â€¢ Single session (small): 1.0-1.5x (minimal gain)")
    print("â€¢ Single session (large): 2.0-3.0x speedup")
    print("â€¢ Multi-session: 2.5-4.0x speedup")
    print("â€¢ Memory-efficient: 1.5-2.5x speedup")


def create_testing_protocol():
    """Provide protocol for testing parallelism on their data."""
    print("\nðŸ§ª TESTING PROTOCOL FOR YOUR DATA")
    print("=" * 50)
    
    print("1. ðŸ”¬ TEST SINGLE SESSION (what you already did):")
    print("   python src/parallelism/test_parallelism.py --real data/processed/all_eeg_data.pkl")
    print("   âœ… COMPLETED - Threading shows 2.9x speedup")
    
    print("\n2. ðŸ§  TEST MULTI-SESSION (recommended next step):")
    print("   python src/parallelism/test_multisession_parallelism.py --rat_id 531")
    print("   â€¢ Tests 3, 6, and 10 sessions")
    print("   â€¢ Compares sequential vs parallel")
    print("   â€¢ Estimates full rat analysis time")
    
    print("\n3. ðŸ’¾ TEST MEMORY-EFFICIENT PIPELINE (most realistic):")
    print("   python src/parallelism/test_memory_efficient_parallelism.py --rat_id 531")
    print("   â€¢ Tests the actual memory-efficient multi-session script")
    print("   â€¢ Most representative of real usage")
    print("   â€¢ Shows where biggest gains are")
    
    print("\n4. ðŸ“ˆ TEST DIFFERENT ROI SIZES:")
    print("   python src/parallelism/test_multisession_parallelism.py --test_scaling")
    print("   â€¢ Tests 2, 4, 8, 16 channel ROIs")
    print("   â€¢ Shows where parallelism threshold is")
    
    print("\n5. ðŸŽ¯ INTEGRATION TESTING:")
    print("   â€¢ Modify nm_theta_multi_session_memory_efficient.py")
    print("   â€¢ Add threading option to channel processing")
    print("   â€¢ Test with full rat analysis")


def main():
    """Main analysis function."""
    print("ðŸš€ COMPREHENSIVE PARALLELISM ANALYSIS")
    print("Based on your test results and EEG analysis patterns")
    print("=" * 60)
    
    # Analyze your results
    your_results = analyze_your_results()
    
    # Predict multi-session performance
    predict_multisession_performance()
    
    # Create recommendations
    create_recommendation_framework()
    
    # Usage guide
    create_usage_guide()
    
    # Testing protocol
    create_testing_protocol()
    
    print(f"\n{'='*60}")
    print("ðŸŽ¯ SUMMARY & NEXT STEPS")
    print("=" * 60)
    
    print("âœ… YOUR RESULTS ARE REALISTIC AND VALUABLE:")
    print("   â€¢ Threading outperforms multiprocessing for EEG analysis")
    print("   â€¢ 2.9x speedup on single session is excellent")
    print("   â€¢ Memory savings with threading are significant")
    
    print("\nðŸš€ RECOMMENDED NEXT STEPS:")
    print("1. Test multi-session scenarios (where biggest gains are)")
    print("2. Test memory-efficient pipeline (most realistic usage)")
    print("3. Consider integrating threading into main codebase")
    
    print("\nðŸ’¡ KEY INSIGHT:")
    print("   Single session results suggest even BIGGER gains")
    print("   for multi-session analysis. Your 2.9x speedup will")
    print("   likely scale to 3-5x for full rat analysis!")
    
    print(f"\n{'='*60}")


if __name__ == "__main__":
    main()